{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pokablive/datasi/blob/main/DS23_preprocessing_%E9%85%8D%E5%B8%83%E7%94%A8_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パッケージのインストール"
      ],
      "metadata": {
        "id": "SrLgL3UoMpQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U typing-extensions"
      ],
      "metadata": {
        "id": "960ToMvv23Ch",
        "outputId": "3c92ac51-cf7b-4632-9d1a-dd10463e995e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install jaxtyping"
      ],
      "metadata": {
        "id": "YZKdvFwY27da",
        "outputId": "8f74f50b-cb7d-4b0b-e491-f8710894f06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.2.22-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (1.23.5)\n",
            "Collecting typeguard>=2.13.3 (from jaxtyping)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (4.8.0)\n",
            "Installing collected packages: typeguard, jaxtyping\n",
            "Successfully installed jaxtyping-0.2.22 typeguard-4.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パッケージのimport"
      ],
      "metadata": {
        "id": "H0Yhep7qMsIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g71EleONtuFw"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence, Any\n",
        "from jaxtyping import Array, Float, Num\n",
        "from typing_extensions import Self\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.base import OneToOneFeatureMixin, TransformerMixin, BaseEstimator\n",
        "\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正規化\n",
        "\n",
        "正規化とは以下の処理を特徴量ごとに行う，データ解析の前処理のこと．\n",
        "\n",
        "$$\n",
        "X_\\text{normal} =\\frac{X-X_{min}}{X_{max}-X_{min}}\n",
        "$$"
      ],
      "metadata": {
        "id": "7DbDmX_9Mw4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn-like apiによる正規化の実装"
      ],
      "metadata": {
        "id": "lZsojsS-vvce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MinMaxScaler(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, in_features=None):\n",
        "        self.in_features = in_features\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if self.in_features is None:\n",
        "            self.in_features_ = np.ones(X.shape[1], dtype=np.bool_)\n",
        "        else:\n",
        "            self.in_features_ = self.in_features\n",
        "        X = X[:,self.in_features_]\n",
        "        self.min_ = X.min(axis=0)\n",
        "        self.max_ = X.max(axis=0)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, \"min_\")\n",
        "        X = X[:,self.in_features_]\n",
        "        transformed = (X - self.min_) / (self.max_ - self.min_)\n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        tranformed = self.transform(X)\n",
        "        return tranformed"
      ],
      "metadata": {
        "id": "ngUSmKht76AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "type hintを使ったバージョン"
      ],
      "metadata": {
        "id": "3hgsDgraOPou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MinMaxScaler(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, in_features: Sequence[int] | None =None)->None:\n",
        "        self.in_features = in_features\n",
        "\n",
        "    def fit(self, X: Num[Array, \"data feature\"], y=None)->Self:\n",
        "        if self.in_features is None:\n",
        "            self.in_features_ = np.ones(X.shape[1], dtype=np.bool_)\n",
        "        else:\n",
        "            self.in_features_ = self.in_features\n",
        "        X = X[:,self.in_features_]\n",
        "        self.min_ = X.min(axis=0)\n",
        "        self.max_ = X.max(axis=0)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: Num[Array, \"data feature\"])->Num[Array, \"data feature\"]:\n",
        "        check_is_fitted(self, \"min_\")\n",
        "        X = X[:,self.in_features_]\n",
        "        transformed = (X - self.min_) / (self.max_ - self.min_)\n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self, X: Num[Array, \"data feature\"])->Num[Array, \"data feature\"]:\n",
        "        self.fit(X)\n",
        "        tranformed = self.transform(X)\n",
        "        return tranformed"
      ],
      "metadata": {
        "id": "nupnZeCNtvYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)"
      ],
      "metadata": {
        "id": "EPNjvq1owHQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MinMaxScaler().transform(X_test)"
      ],
      "metadata": {
        "id": "L2DrnBk8wdTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MinMaxScaler([0,1]).fit(X_train).transform(X_test)"
      ],
      "metadata": {
        "id": "Oa69a2v1wsJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 標準化\n",
        "\n",
        "標準化とは以下の処理を特徴量ごとに行う，データ解析の前処理のこと．\n",
        "\n",
        "\n",
        "$$\n",
        "X_{std} = \\frac{X-\\mu}{\\sigma_X}\n",
        "$$"
      ],
      "metadata": {
        "id": "6OtrZ8d2AtJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn-like APIによる標準化の実装\n",
        "\n",
        "MinMaxScalerクラスを参考に，標準化を実装せよ．"
      ],
      "metadata": {
        "id": "oXgtiKdPNPJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MinMaxScaler(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, in_features: Sequence[int] | None =None)->None:\n",
        "        self.in_features = in_features\n",
        "\n",
        "    def fit(self, X: Num[Array, \"data feature\"], y=None)->Self:\n",
        "        if self.in_features is None:\n",
        "            self.in_features_ = np.ones(X.shape[1], dtype=np.bool_)\n",
        "        else:\n",
        "            self.in_features_ = self.in_features\n",
        "        X = X[:,self.in_features_]\n",
        "        self.min_ = X.min(axis=0)\n",
        "        self.max_ = X.max(axis=0)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: Num[Array, \"data feature\"])->Num[Array, \"data feature\"]:\n",
        "        check_is_fitted(self, \"min_\")\n",
        "        X = X[:,self.in_features_]\n",
        "        transformed = (X - self.min_) / (self.max_ - self.min_)\n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self, X: Num[Array, \"data feature\"])->Num[Array, \"data feature\"]:\n",
        "        self.fit(X)\n",
        "        tranformed = self.transform(X)\n",
        "        return tranformed"
      ],
      "metadata": {
        "id": "x88YWe4UxwN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StandardScaler(ddof=1).fit(X_train).transform(X_test)"
      ],
      "metadata": {
        "id": "zMbvElevN-3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StandardScaler(ddof=0).fit(X_train).transform(X_test)"
      ],
      "metadata": {
        "id": "ltoCuYy2OCxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StandardScaler([0,1]).fit(X_train).transform(X_test)"
      ],
      "metadata": {
        "id": "jtfZO02EGXBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StandardScaler([0,1]).transform(X_test)"
      ],
      "metadata": {
        "id": "m3iGFeO7Gdtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTIMmdMHGwOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}